#############################################################################
# Copyright (c) 2022 NVIDIA Corporation.  All rights reserved.
#
# NVIDIA Corporation and its licensors retain all intellectual property
# and proprietary rights in and to this software, related documentation
# and any modifications thereto.  Any use, reproduction, disclosure or
# distribution of this software and related documentation without an express
# license agreement from NVIDIA Corporation is strictly prohibited.
#############################################################################

This sample is meant for simple demonstration of how to capture color and depth
information from a 3D camera like realsense (DS435).

This sample uses the "NvDs3dSrc" component to read data from the 3D camera, the
"NvDs3dFilter" component to perform operations on 3D data like converting the
color and depth info into a 3D point/color cloud and the "NvDs3dSink" component
to render 3D information either as a 2D image or as a 3D point cloud.

The three components are configured using configuration files. Sample configuration
files for each of the components have been provided.

* ds_3d_loader_realsense.yaml - 3D Data Loader (src) configuration for realsense
                                camera
* ds_3d_filter_depth2cloud.yaml - 3D Data filter configuration for converting
                                  depth & color information to 3D point cloud
* ds_3d_render_pointcloud3d.yaml - Data Render (sink) configuration for rendering
                                   point cloud buffer in 3D. Mouse interactions
                                   are possible
* ds_3d_render_depth2d.yaml - Data Render (src) configuration for rendering depth
                              & cloud information in 2D

Additional components "NvDs3dDataDepthInfoLogger", "NvDs3dDataColorInfoLogger"
and "NvDs3dDataPointCloudInfoLogger" are used to print some information about the
3D data to stdout and optionally write the raw buffers to file.

For more information on DeepStream 3D pipeline, components and configuration details
refer to the DeepStream documentation at
https://docs.nvidia.com/metropolis/deepstream/dev-guide/index.html

================================================================================
Pre-requisites
================================================================================
- DeepStreamSDK 6.2
- Graph-Composer 2.5.0
- Realsense SDK

Follow Realsense SDK documentation to add realsense public key and list of repositories.
https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md
Then install librealsense2 package for build and test.
   sudo apt-get install librealsense2-utils librealsense2-dev

For Jetson platform, refer to
https://github.com/IntelRealSense/librealsense/blob/master/doc/installation_jetson.md
Until Realsense provides Ubuntu 20.04 support on Jetson, users can add Ubuntu 18.04
source path into apt-repository.
sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo bionic main" -u

================================================================================
Running the graph
================================================================================
On x86:
$ /opt/nvidia/graph-composer/execute_graph.sh deepstream-3d-camera.yaml \
      -d ../common/target_x86_64.yaml

On Jetson:
$ /opt/nvidia/graph-composer/execute_graph.sh deepstream-3d-camera.yaml \
      -d ../common/target_aarch64.yaml

NOTE: "parameters-2drender.yaml" can be added to the commandline to render 2D
depth/color images instead of the default 3D point cloud rendering.

NOTE: Mouse interactions are possible with default 3D point render.

================================================================================
Building application(graph) specific container image
================================================================================
The Graph-Composer Container Builder tool can be used to build application(graph)
specific containers. The container builder configuration files have already been
provided for this sample.

* Building a DGPU container and running on the same host
  $ container_builder -c ds_3d_depth_camera_container_builder_dgpu.yaml \
        -d ../common/target_x86_64.yaml
  $ xhost +
  $ docker run -it --rm --gpus all --device /dev/video0 --device /dev/video1 \
        --device /dev/video2 --device /dev/video3 --device /dev/video4 \
        --device /dev/video5  -v /tmp/.X11-unix/:/tmp/.X11-unix/ -e DISPLAY=:0 \
        deepstream_3d_depth_camera_dgpu
