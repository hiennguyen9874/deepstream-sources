################################################################################
# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
#
# NVIDIA Corporation and its licensors retain all intellectual property
# and proprietary rights in and to this software, related documentation
# and any modifications thereto.  Any use, reproduction, disclosure or
# distribution of this software and related documentation without an express
# license agreement from NVIDIA Corporation is strictly prohibited.
#
################################################################################

This sample shows how to use a re-identification model for multi-object tracking
like NvDeepSORT on dGPU and Jetson.

--------------------------------------------------------------------------------
Pre-requisites:
- Visit official DeepSORT GitHub repo https://github.com/nwojke/deep_sort
  In section "Installation", there is a link to the pre-trained re-identification
  model. Download the model file `networks/mars-small128.pb` and place it under
  the current directory `sources/tracker_NvDeepSORT/`.
- Generate UFF model from TensorFlow frozen graph. The generation process can be
  done on both dGPU and Jetson; or the UFF model can be generated on dGPU first
  and copied to Jetson.
  1. Package uff-converter-tf and graphsurgeon-tf should be already installed with
     TensorRT.
  2. Install PyYAML and tensorflow-gpu (version 1.15 recommended, but 2+ also fine):
     For dGPU:
       $ pip3 install tensorflow-gpu PyYAML
     For Jetson, refer to
     https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html
  3. Run provided script to convert pb model into uff file. The default location is
     `/opt/nvidia/deepstream/deepstream/samples/models/Tracker/mars-small128.uff`
     $ python3 convert.py
- (Optional) Above steps setup NvDeepSORT with fp32/16 precision. To maximize the
  performance, int8 precision inference can be enabled with a calibration file.
  1. Find a list of image patches for TensorRT calibration. They should have the same
  size as network input and provide a representative set of input data. For the official
  model, they should be single person crops with 128x64 size. Save them under
  `source/tracker_NvDeepSORT/data/`.
  2. Install dependencies
     $ pip3 install numpy pycuda Pillow
  3. Update network mode in NvDeepSORT tracker config file (using batch size=100 for example)
     networkMode: 2
     modelEngineFile: "/opt/nvidia/deepstream/deepstream/samples/models/Tracker/mars-small128.uff_b100_gpu0_int8.engine"
     calibrationTableFile: "/opt/nvidia/deepstream/deepstream/samples/models/Tracker/calibration.cache"
  4. Run provided script to generate calibration table for int8 inference.
     $ python3 calibrate.py

--------------------------------------------------------------------------------
Run the sample:
- Enter `samples/configs/deepstream-app/`. In deepstream-app config, change
  [tracker] config to use NvDeepSORT:
  ll-config-file=config_tracker_NvDeepSORT.yml
  NvDeepSORT tracker parameters are in `config_tracker_NvDeepSORT.yml`.
- Run deepstream-app
  deepstream-app -c <path to config.txt>
